{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-09T10:22:35.761756Z",
     "start_time": "2025-07-09T10:22:35.757678Z"
    }
   },
   "source": [
    ""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-09T10:22:36.767061Z",
     "start_time": "2025-07-09T10:22:35.901288Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class WeightedLayerPooling(nn.Module):\n",
    "    def __init__(self, num_hidden_layers, layer_start: int = 4):\n",
    "        super().__init__()\n",
    "        # layer_start表示我们从倒数第几层开始用\n",
    "        self.layer_start = layer_start\n",
    "        self.num_layers_to_pool = num_hidden_layers - layer_start + 1\n",
    "\n",
    "        # 定义可学习的权重，初始化为1\n",
    "        # 这样在训练开始时，它等价于一个简单的平均\n",
    "        self.layer_weights = nn.Parameter(\n",
    "            torch.ones(self.num_layers_to_pool)\n",
    "        )\n",
    "\n",
    "    def forward(self, all_hidden_states):\n",
    "        # 1. 选取我们需要的层\n",
    "        # all_hidden_states 是一个 tuple, 我们把它转成 tensor\n",
    "        # 我们要的是模型最后几层，所以从后面开始取\n",
    "        layers_to_pool = torch.stack(\n",
    "            all_hidden_states[-self.num_layers_to_pool:],\n",
    "            dim=0\n",
    "        )  # Shape: (num_layers, batch, seq_len, hidden_dim)\n",
    "\n",
    "        # 2. 计算权重\n",
    "        # 为了让权重更稳定且具有可解释性，通常会用softmax\n",
    "        # 这样所有权重加起来等于1，代表了贡献度的百分比\n",
    "        weight_softmax = torch.softmax(self.layer_weights, dim=0)\n",
    "\n",
    "        # 3. 调整权重形状以进行广播 (broadcast)\n",
    "        # 从 (num_layers,) 变成 (num_layers, 1, 1, 1)\n",
    "        # 这样它就可以和 (num_layers, batch, seq_len, hidden_dim) 的层输出相乘\n",
    "        reshaped_weights = weight_softmax.view(-1, 1, 1, 1)\n",
    "\n",
    "        # 4. 执行加权求和\n",
    "        # 两个张量相乘，然后在一个维度上求和\n",
    "        weighted_average = torch.sum(layers_to_pool * reshaped_weights, dim=0)\n",
    "\n",
    "        return weighted_average  # Shape: (batch, seq_len, hidden_dim)"
   ],
   "id": "2c9f8470b3f2bc82",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ouyanganqi/miniconda3/envs/myenv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-09T10:22:37.297299Z",
     "start_time": "2025-07-09T10:22:36.790899Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "esm_model = AutoModel.from_pretrained(\n",
    "    \"../../scoures/ESM2-35M\",\n",
    "    trust_remote_code=True,\n",
    "    output_hidden_states=True  # 确保获取所有层输出\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"../../scoures/ESM2-35M\",\n",
    "    trust_remote_code=True)"
   ],
   "id": "c804502ffbf5c12",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.6 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"/home/ouyanganqi/miniconda3/envs/myenv/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/home/ouyanganqi/miniconda3/envs/myenv/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/home/ouyanganqi/miniconda3/envs/myenv/lib/python3.10/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/home/ouyanganqi/miniconda3/envs/myenv/lib/python3.10/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/home/ouyanganqi/miniconda3/envs/myenv/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/home/ouyanganqi/miniconda3/envs/myenv/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/home/ouyanganqi/miniconda3/envs/myenv/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/home/ouyanganqi/miniconda3/envs/myenv/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n",
      "    handle._run()\n",
      "  File \"/home/ouyanganqi/miniconda3/envs/myenv/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/home/ouyanganqi/miniconda3/envs/myenv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/home/ouyanganqi/miniconda3/envs/myenv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/home/ouyanganqi/miniconda3/envs/myenv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"/home/ouyanganqi/miniconda3/envs/myenv/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/home/ouyanganqi/miniconda3/envs/myenv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/home/ouyanganqi/miniconda3/envs/myenv/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/home/ouyanganqi/miniconda3/envs/myenv/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/home/ouyanganqi/miniconda3/envs/myenv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3077, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/home/ouyanganqi/miniconda3/envs/myenv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3132, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/home/ouyanganqi/miniconda3/envs/myenv/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/home/ouyanganqi/miniconda3/envs/myenv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3336, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/home/ouyanganqi/miniconda3/envs/myenv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3519, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/home/ouyanganqi/miniconda3/envs/myenv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3579, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_39330/579515825.py\", line 3, in <module>\n",
      "    esm_model = AutoModel.from_pretrained(\n",
      "  File \"/home/ouyanganqi/miniconda3/envs/myenv/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py\", line 463, in from_pretrained\n",
      "    return model_class.from_pretrained(\n",
      "  File \"/home/ouyanganqi/miniconda3/envs/myenv/lib/python3.10/site-packages/transformers/modeling_utils.py\", line 2230, in from_pretrained\n",
      "    state_dict = load_state_dict(resolved_archive_file)\n",
      "  File \"/home/ouyanganqi/miniconda3/envs/myenv/lib/python3.10/site-packages/transformers/modeling_utils.py\", line 397, in load_state_dict\n",
      "    return safe_load_file(checkpoint_file)\n",
      "  File \"/home/ouyanganqi/miniconda3/envs/myenv/lib/python3.10/site-packages/safetensors/torch.py\", line 315, in load_file\n",
      "    result[k] = f.get_tensor(k)\n",
      "  File \"/home/ouyanganqi/miniconda3/envs/myenv/lib/python3.10/site-packages/torch/storage.py\", line 233, in __getitem__\n",
      "    return super().__getitem__(*args, **kwargs)\n",
      "/home/ouyanganqi/miniconda3/envs/myenv/lib/python3.10/site-packages/torch/storage.py:233: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:77.)\n",
      "  return super().__getitem__(*args, **kwargs)\n",
      "Some weights of the model checkpoint at ../../scoures/ESM2-35M were not used when initializing EsmModel: ['lm_head.bias', 'esm.contact_head.regression.bias', 'esm.contact_head.regression.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing EsmModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing EsmModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of EsmModel were not initialized from the model checkpoint at ../../scoures/ESM2-35M and are newly initialized: ['esm.pooler.dense.weight', 'esm.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-09T10:22:37.316377Z",
     "start_time": "2025-07-09T10:22:37.312896Z"
    }
   },
   "cell_type": "code",
   "source": [
    "esm_config = esm_model.config\n",
    "embedding_size = esm_config.hidden_size\n",
    "\n",
    "weighted_pooling = WeightedLayerPooling(\n",
    "    num_hidden_layers=esm_config.num_hidden_layers,\n",
    "    layer_start=esm_config.num_hidden_layers - 4\n",
    ")"
   ],
   "id": "33f67ddc1c95846f",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-09T10:22:37.416834Z",
     "start_time": "2025-07-09T10:22:37.351624Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../../data/EC_X_val_40.csv\")\n",
    "sequences = df[\"SEQUENCE\"].tolist()[:100]  # 取前100个序列进行测试\n",
    "inputs = tokenizer(\n",
    "    sequences,\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    return_tensors=\"pt\"\n",
    ")\n",
    "inputs_ids = inputs[\"input_ids\"]\n",
    "attention_mask = inputs[\"attention_mask\"]"
   ],
   "id": "3015f7ee209f6c1f",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-09T10:22:38.203578Z",
     "start_time": "2025-07-09T10:22:37.454906Z"
    }
   },
   "cell_type": "code",
   "source": [
    "esm_outputs = esm_model(\n",
    "    input_ids=inputs_ids,\n",
    "    attention_mask=attention_mask\n",
    ")\n",
    "all_hidden_states = esm_outputs.hidden_states\n",
    "\n",
    "# B. 使用层权重融合，得到一个增强的ESM序列表示\n",
    "esm_output_fused = weighted_pooling(all_hidden_states)\n",
    "esm_output_fused.shape"
   ],
   "id": "6351d4f5330f7eea",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 42, 480])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-09T10:22:38.322076Z",
     "start_time": "2025-07-09T10:22:38.317145Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tokenizer(\n",
    "    sequences[1],\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    return_tensors=\"pt\"\n",
    ")"
   ],
   "id": "66640ba9ef9e2a24",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 0,  6, 15,  4,  4,  8,  4,  4,  8,  4,  4,  6,  4,  4,  2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-09T10:22:38.857024Z",
     "start_time": "2025-07-09T10:22:38.436859Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "from mic_model import MyDataset\n",
    "\n",
    "dataset = MyDataset(\n",
    "    df=df,\n",
    "    tokenizer=tokenizer,\n",
    "    max_length=1024\n",
    ")\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    batch_size=256,\n",
    "    shuffle=False,\n",
    "    collate_fn=data_collator\n",
    ")"
   ],
   "id": "b3bd85c3a347a834",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-09T11:34:18.793550Z",
     "start_time": "2025-07-09T11:34:18.771188Z"
    }
   },
   "cell_type": "code",
   "source": "next(iter(dataloader))[\"genome\"].shape",
   "id": "6f503757d43a879d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 84])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
